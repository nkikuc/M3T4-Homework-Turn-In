### FUTURE DIARY 1.0
##### (This is an excerpt from an interview with the director Eddie Warren on his 25th anniversary since the release of his first AI generated film *Will Electric Sheep Dream of Androids?*)

(*When asked about the filming process with the live actor.*) Typically, we call them (eye actors) pretty early in the process. The (eye) Actors tend to come up with surprising ideas that none of the production designers ever even thought of. Especially when it comes to things about the characters. So it works better if they come at the earlier stage where we are still brushing up on the screen play and other design elements. We usually ask the live (eye) actor to come for about a two day shoot. The actual shooting is pretty short. The truth is, we don't need real actors to reference for much of the generated footages, because none of the people we generate is real *laughs*. The reason for the live actor is really for their eyes to merge onto the AI generated footages' eyes. This helps the footage look far more real and alive. It's really about the eyes. To be honest, a lot of the acting comes from the editing and camera works. A sense of  can be shown from a low angle shot looking up at the actor. If we change that to a high angle shot, the actor suddenly appears weakened. The only thing we can't recreate is the life shown in the eyes. And the audience today is surprisingly sensitive about this. Especially today, when there is so many (AI) generated images, the audience is quite keen to wether an image is of real humans or not. The dividing factor of this is mostly the eyes. Hair also, I guess. We still need reference live actors for hair. AI isn't good at generating hair. But, yeah... That's about it. I mean, you can't just show case an existing human to the public. It's quite dangerous to just release real human footages, you can never imagine what certain people will do with it *a wry smile*.

### FUTURE DIARY 2.0
##### (A news report following a shut down of a 3D Computer Graphics department of a film studio)

####### BREAKING: PennyWorks Studio Will Shutdown 3D Computer Graphics Special Effects Department; 300 Jobs Will Be Lost
By ANDREW COSTNER 04/22/31 1:00 PM

PennyWorks Studio chief Frederic Wiseman emphasized that the decision had nothing to do with financial issues, but rather because the studio wanted to keep up with the rapidly evolving technology of AI generated CGI, or AGI as it is commonly referred to. This follows the trend of the Hollywood movie industry moving towards the AI generated special effects rather than the traditional 3D Computer Graphics used to recreate explosions and such.

The closing of the department will start immediately. The studio is expected to hold one on one meetings with the CGI artists offering them opportunities to move to the newly established AGI department.

The closing is part of the company's "On going review to ensure the Studio's operational structure align with the demands of the current marketplace." However the 3D animation and modeling department still seems to be safe from any layoffs or cut down. This sudden shutdown has still taken the public by surprise, and many notable figures had expressed great sadness and shocks.
